{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTTrr2c3RoHl"
      },
      "source": [
        "# **Step 1: Set Up the Environment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HUbZmlhRRaJ"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIciOZfqRclY"
      },
      "outputs": [],
      "source": [
        "# Load the datasets\n",
        "file_paths = {\n",
        "    \"all_data_1\": \"all_data_1.csv\",\n",
        "    \"all_data_2\": \"all_data_2_words.csv\",\n",
        "    \"all_data_3\": \"all_data_3_words.csv\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACOi8zdLRtBx"
      },
      "outputs": [],
      "source": [
        "# Load the datasets into pandas DataFrames\n",
        "datasets = {name: pd.read_csv(path) for name, path in file_paths.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OD0CWSlIR_hd"
      },
      "source": [
        "# **Step 2: Preprocessing**\n",
        "Since this is a time-series classification problem, we need to ensure:\n",
        "\n",
        "1. Input (X): Sequences of sensor values over time.\n",
        "2. Output (Y): Corresponding labels for the entire sequence.\n",
        "\n",
        "Let's modify the preprocessing workflow to:\n",
        "\n",
        "1. Group sensor readings by sequence.\n",
        "2. Prepare sequences (as X) and their corresponding label (Y).\n",
        "\n",
        "Updated Workflow for Time-Series Data\n",
        "\n",
        "1. **Group Data:** Ensure each sequence is grouped by the corresponding Letter.\n",
        "2. **Create Time-Series Inputs and Labels:** Prepare X as sequences of sensor data for each label. Assign Y as the corresponding label for the sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCYW2wxAT7UR"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVr2YNK1T_5E",
        "outputId": "2eca833b-eeb8-47e2-aa86-c3a0580d2cac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-318-a44e796990f6>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_data[sensor_columns] = scaler.fit_transform(filtered_data[sensor_columns])\n"
          ]
        }
      ],
      "source": [
        "# Combine datasets\n",
        "combined_data = pd.concat([datasets[\"all_data_1\"], datasets[\"all_data_2\"], datasets[\"all_data_3\"]], ignore_index=True)\n",
        "\n",
        "# Filter out noise\n",
        "filtered_data = combined_data[combined_data[\"Letter\"] != \"noise\"]\n",
        "\n",
        "# Define sensor columns\n",
        "sensor_columns = ['Acc_X', 'Acc_Y', 'Acc_Z', 'Gyro_X', 'Gyro_Y', 'Gyro_Z', 'Mag_X', 'Mag_Y', 'Mag_Z', 'Force1', 'Force2', 'Force3', 'IR1_A', 'IR2_A']\n",
        "\n",
        "# Normalize sensor data (Z-score normalization)\n",
        "scaler = StandardScaler()\n",
        "filtered_data[sensor_columns] = scaler.fit_transform(filtered_data[sensor_columns])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSV5tS-ESfU1"
      },
      "outputs": [],
      "source": [
        "# Function to group data into sequences by label\n",
        "def create_sequences(data):\n",
        "    sequences = []\n",
        "    labels = []\n",
        "    current_label = None\n",
        "    current_sequence = []\n",
        "\n",
        "    for _, row in data.iterrows():\n",
        "        if row[\"Letter\"] != current_label:\n",
        "            # Save the current sequence if it's not empty\n",
        "            if current_sequence:\n",
        "                sequences.append(np.array(current_sequence))\n",
        "                labels.append(current_label)\n",
        "            # Start a new sequence\n",
        "            current_label = row[\"Letter\"]\n",
        "            current_sequence = []\n",
        "\n",
        "        # Append sensor values to the current sequence\n",
        "        current_sequence.append(row[sensor_columns].values)\n",
        "\n",
        "    # Save the final sequence\n",
        "    if current_sequence:\n",
        "        sequences.append(np.array(current_sequence))\n",
        "        labels.append(current_label)\n",
        "\n",
        "    return np.array(sequences, dtype=object), labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwYUQ5YcTuO4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "# Create sequences and labels\n",
        "sequences, labels = create_sequences(filtered_data)\n",
        "\n",
        "# Map labels to integer indices\n",
        "unique_labels = list(set(labels))\n",
        "max_label_length = max([len(label) for label in unique_labels])\n",
        "characters = set(char for label in unique_labels for char in label)\n",
        "\n",
        "# Mapping characters to integers\n",
        "char_to_num = layers.StringLookup(\n",
        "    vocabulary=list(characters), mask_token=None\n",
        ")\n",
        "\n",
        "# Mapping integers back to original characters\n",
        "num_to_char = layers.StringLookup(\n",
        "    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",
        ")\n",
        "\n",
        "''' def split_data(sequences, labels, train_size=0.7, shuffle=True):\n",
        "    # 1. Get the total size of the dataset\n",
        "    size = len(sequences)\n",
        "    # 2. Make an indices array and shuffle it, if required\n",
        "    indices = np.arange(size)\n",
        "    if shuffle:\n",
        "        np.random.shuffle(indices)\n",
        "    # 3. Get the size of training samples\n",
        "    train_samples = int(size * train_size)\n",
        "    # 4. Split data into training and validation sets\n",
        "    x_train, y_train = sequences[indices[:train_samples]], labels[indices[:train_samples]]\n",
        "    x_valid, y_valid = sequences[indices[train_samples:]], labels[indices[train_samples:]]\n",
        "    return x_train, x_valid, y_train, y_valid\n",
        "\n",
        "# Splitting data into training and validation sets\n",
        "x_train, x_valid, y_train, y_valid = split_data(np.array(sequences), np.array(labels)) '''\n",
        "\n",
        "# Print all\n",
        "labels = [char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\")) for label in labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQ4wSp-JVKKM",
        "outputId": "90341bc5-d87c-4e04-b727-61ef343db7ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Padded Sequences Shape: (79, 64, 11)\n",
            "Filtered Labels Count: 79\n",
            "Max length:  64\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Define padding parameters\n",
        "max_length = max([len(seq) for seq in sequences])  # Longest sequence\n",
        "min_length = 10  # Minimum acceptable length for sequences\n",
        "\n",
        "# Filter out very short sequences\n",
        "filtered_sequences = [seq for seq in sequences if seq.shape[0] >= min_length]\n",
        "filtered_labels = [label for seq, label in zip(sequences, labels) if seq.shape[0] >= min_length]\n",
        "\n",
        "# Pad sequences to the same length\n",
        "padded_sequences = pad_sequences(filtered_sequences, maxlen=max_length, padding='post', dtype='float32', value=0)\n",
        "\n",
        "# Verify the new shapes\n",
        "print(f\"Padded Sequences Shape: {padded_sequences.shape}\")\n",
        "print(f\"Filtered Labels Count: {len(filtered_labels)}\")\n",
        "\n",
        "print(\"Max length: \", max_length)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1B_NERgHXJA5",
        "outputId": "ff5a0553-23b2-4ddc-fd58-f4f7d136c45c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequence Shape: (64, 11), Label: [5]\n",
            "Sequence Shape: (64, 11), Label: [10]\n",
            "Sequence Shape: (64, 11), Label: [31]\n",
            "Sequence Shape: (64, 11), Label: [16]\n",
            "Sequence Shape: (64, 11), Label: [36]\n",
            "Sequence Shape: (64, 11), Label: [23]\n",
            "Sequence Shape: (64, 11), Label: [17]\n",
            "Sequence Shape: (64, 11), Label: [26]\n",
            "Sequence Shape: (64, 11), Label: [52]\n",
            "Sequence Shape: (64, 11), Label: [25]\n",
            "Sequence Shape: (64, 11), Label: [28]\n",
            "Sequence Shape: (64, 11), Label: [11]\n",
            "Sequence Shape: (64, 11), Label: [32]\n",
            "Sequence Shape: (64, 11), Label: [59]\n",
            "Sequence Shape: (64, 11), Label: [39]\n",
            "Sequence Shape: (64, 11), Label: [51]\n",
            "Sequence Shape: (64, 11), Label: [46]\n",
            "Sequence Shape: (64, 11), Label: [49]\n",
            "Sequence Shape: (64, 11), Label: [33]\n",
            "Sequence Shape: (64, 11), Label: [6]\n",
            "Sequence Shape: (64, 11), Label: [2]\n",
            "Sequence Shape: (64, 11), Label: [13]\n",
            "Sequence Shape: (64, 11), Label: [37]\n",
            "Sequence Shape: (64, 11), Label: [43]\n",
            "Sequence Shape: (64, 11), Label: [54]\n",
            "Sequence Shape: (64, 11), Label: [44]\n",
            "Sequence Shape: (64, 11), Label: [19]\n",
            "Sequence Shape: (64, 11), Label: [45]\n",
            "Sequence Shape: (64, 11), Label: [40]\n",
            "Sequence Shape: (64, 11), Label: [41]\n",
            "Sequence Shape: (64, 11), Label: [4]\n",
            "Sequence Shape: (64, 11), Label: [30]\n",
            "Sequence Shape: (64, 11), Label: [38]\n",
            "Sequence Shape: (64, 11), Label: [34]\n",
            "Sequence Shape: (64, 11), Label: [53]\n",
            "Sequence Shape: (64, 11), Label: [58]\n",
            "Sequence Shape: (64, 11), Label: [62]\n",
            "Sequence Shape: (64, 11), Label: [9]\n",
            "Sequence Shape: (64, 11), Label: [12]\n",
            "Sequence Shape: (64, 11), Label: [18]\n",
            "Sequence Shape: (64, 11), Label: [47]\n",
            "Sequence Shape: (64, 11), Label: [55]\n",
            "Sequence Shape: (64, 11), Label: [20]\n",
            "Sequence Shape: (64, 11), Label: [42]\n",
            "Sequence Shape: (64, 11), Label: [29]\n",
            "Sequence Shape: (64, 11), Label: [22]\n",
            "Sequence Shape: (64, 11), Label: [56]\n",
            "Sequence Shape: (64, 11), Label: [57]\n",
            "Sequence Shape: (64, 11), Label: [7]\n",
            "Sequence Shape: (64, 11), Label: [3]\n",
            "Sequence Shape: (64, 11), Label: [8]\n",
            "Sequence Shape: (64, 11), Label: [61]\n",
            "Sequence Shape: (64, 11), Label: [60]\n",
            "Sequence Shape: (64, 11), Label: [24]\n",
            "Sequence Shape: (64, 11), Label: [15]\n",
            "Sequence Shape: (64, 11), Label: [1]\n",
            "Sequence Shape: (64, 11), Label: [27]\n",
            "Sequence Shape: (64, 11), Label: [48]\n",
            "Sequence Shape: (64, 11), Label: [35]\n",
            "Sequence Shape: (64, 11), Label: [21]\n",
            "Sequence Shape: (64, 11), Label: [50]\n",
            "Sequence Shape: (64, 11), Label: [14]\n",
            "Sequence Shape: (64, 11), Label: [34 53]\n",
            "Sequence Shape: (64, 11), Label: [12  8]\n",
            "Sequence Shape: (64, 11), Label: [18 19 12  4]\n",
            "Sequence Shape: (64, 11), Label: [53 29]\n",
            "Sequence Shape: (64, 11), Label: [22 56 18 19]\n",
            "Sequence Shape: (64, 11), Label: [19 18 41]\n",
            "Sequence Shape: (64, 11), Label: [53]\n",
            "Sequence Shape: (64, 11), Label: [19 12]\n",
            "Sequence Shape: (64, 11), Label: [15  1]\n",
            "Sequence Shape: (64, 11), Label: [ 8  4 19 42 29]\n",
            "Sequence Shape: (64, 11), Label: [47  9 41]\n",
            "Sequence Shape: (64, 11), Label: [22 34 53 29]\n",
            "Sequence Shape: (64, 11), Label: [53 29]\n",
            "Sequence Shape: (64, 11), Label: [47 56 42]\n",
            "Sequence Shape: (64, 11), Label: [30 53 42 29 22]\n",
            "Sequence Shape: (64, 11), Label: [ 7 47 42 41]\n",
            "Sequence Shape: (64, 11), Label: [41 19 22 19 29  4 22]\n"
          ]
        }
      ],
      "source": [
        "for seq, label in zip(padded_sequences, filtered_labels):\n",
        "    print(f\"Sequence Shape: {seq.shape}, Label: {label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOgdMqu3Uxit",
        "outputId": "b82064fb-decd-4f81-e734-97ab74377f2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (79, 64, 11)\n",
            "y_train shape: 79\n",
            "X_test shape: (79, 64, 11)\n",
            "y_test shape: 79\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = padded_sequences, padded_sequences, filtered_labels, filtered_labels\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {len(y_train)}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test shape: {len(y_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNU-advUS0bE"
      },
      "source": [
        "# **Step 3: Model Design**\n",
        "We’ll implement two models:\n",
        "\n",
        "* **CNN Model:** Four 1D convolutional layers. Batch normalization, ReLU activation, and max pooling after each convolutional layer. Fully connected layer for classification.\n",
        "* **CLDNN Model:** Three 1D convolutional layers. Two BLSTM layers for temporal modeling. Fully connected layer for final output.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCHtH6SwXxZz"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, TimeDistributed, Conv1D, BatchNormalization, ReLU, MaxPooling1D, Dense, Dropout, Flatten, Activation, Bidirectional, LSTM\n",
        "import tensorflow as tf\n",
        "\n",
        "def create_cnn_model(input_shape, num_classes):\n",
        "    inputs = Input(shape=input_shape, name='sequence')\n",
        "    x = Conv1D(1024, kernel_size=5, padding=\"same\", name=\"Conv1\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    x = Conv1D(512, kernel_size=3, padding=\"same\", name=\"Conv2\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    x = Conv1D(256, kernel_size=3, padding=\"same\", name=\"Conv3\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    ''' x = Conv1D(128, kernel_size=3, padding=\"same\", name=\"Conv4\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = MaxPooling1D(pool_size=2, name=\"Pool1\")(x)\n",
        "    x = Dropout(0.3)(x) '''\n",
        "\n",
        "    # Ensure time-distributed outputs\n",
        "    x = TimeDistributed(Dense(num_classes), name=\"Time1\")(x)\n",
        "\n",
        "    outputs = Activation('softmax')(x)\n",
        "\n",
        "    return tf.keras.Model(inputs, outputs, name=\"cnn_model\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yK0nbwzrX2oX"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import LSTM, Bidirectional, TimeDistributed\n",
        "\n",
        "def create_cldnn_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        # Convolutional layers\n",
        "        Conv1D(512, kernel_size=5, padding=\"same\", input_shape=input_shape),\n",
        "        BatchNormalization(),\n",
        "        ReLU(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Conv1D(256, kernel_size=3, padding=\"same\"),\n",
        "        BatchNormalization(),\n",
        "        ReLU(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Conv1D(128, kernel_size=3, padding=\"same\"),\n",
        "        BatchNormalization(),\n",
        "        ReLU(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        # Bidirectional LSTMs\n",
        "        Bidirectional(LSTM(64, return_sequences=True, activation=\"tanh\")),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Bidirectional(LSTM(64, return_sequences=True, activation=\"tanh\")),  # Set return_sequences=True\n",
        "        Dropout(0.3),\n",
        "\n",
        "        # TimeDistributed dense layers for sequence output\n",
        "        TimeDistributed(Dense(100, activation=\"relu\")),\n",
        "        TimeDistributed(Dense(num_classes, activation=\"softmax\"))  # Keep softmax for output distribution\n",
        "    ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WtTQIwXeYA-H",
        "outputId": "47ee3691-ecd7-43e5-e356-468214629424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Shape: (64, 11)\n",
            "Number of Classes: 62\n",
            "CNN Model Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"cnn_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"cnn_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequence (\u001b[38;5;33mInputLayer\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m11\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1 (\u001b[38;5;33mConv1D\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1024\u001b[0m)            │          \u001b[38;5;34m57,344\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_118              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1024\u001b[0m)            │           \u001b[38;5;34m4,096\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_118 (\u001b[38;5;33mReLU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1024\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_115 (\u001b[38;5;33mMaxPooling1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_152 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv2 (\u001b[38;5;33mConv1D\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │       \u001b[38;5;34m1,573,376\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_119              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_119 (\u001b[38;5;33mReLU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_116 (\u001b[38;5;33mMaxPooling1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_153 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv3 (\u001b[38;5;33mConv1D\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │         \u001b[38;5;34m393,472\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_120              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_120 (\u001b[38;5;33mReLU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_117 (\u001b[38;5;33mMaxPooling1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_154 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Time1 (\u001b[38;5;33mTimeDistributed\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m62\u001b[0m)               │          \u001b[38;5;34m15,934\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_24 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m62\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequence (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">57,344</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_118              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_118 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_115 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_152 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,573,376</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_119              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_119 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_116 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_153 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">393,472</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_120              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_120 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_117 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_154 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Time1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">15,934</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,047,294\u001b[0m (7.81 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,047,294</span> (7.81 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,043,710\u001b[0m (7.80 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,043,710</span> (7.80 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,584\u001b[0m (14.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,584</span> (14.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CLDNN Model Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_17\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_17\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_103 (\u001b[38;5;33mConv1D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │          \u001b[38;5;34m28,672\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_121              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_121 (\u001b[38;5;33mReLU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_118 (\u001b[38;5;33mMaxPooling1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_155 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_104 (\u001b[38;5;33mConv1D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │         \u001b[38;5;34m393,472\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_122              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_122 (\u001b[38;5;33mReLU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_119 (\u001b[38;5;33mMaxPooling1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_156 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_105 (\u001b[38;5;33mConv1D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │          \u001b[38;5;34m98,432\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_123              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_123 (\u001b[38;5;33mReLU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_120 (\u001b[38;5;33mMaxPooling1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_157 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_34 (\u001b[38;5;33mBidirectional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │          \u001b[38;5;34m98,816\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_158 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_35 (\u001b[38;5;33mBidirectional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │          \u001b[38;5;34m98,816\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_159 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_47                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m100\u001b[0m)              │          \u001b[38;5;34m12,900\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_48                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m62\u001b[0m)               │           \u001b[38;5;34m6,262\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_103 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">28,672</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_121              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_121 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_118 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_155 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_104 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">393,472</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_122              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_122 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_119 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_156 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_105 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_123              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_123 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_120 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_157 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_158 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_159 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_47                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,900</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_48                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,262</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m740,954\u001b[0m (2.83 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">740,954</span> (2.83 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m739,162\u001b[0m (2.82 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">739,162</span> (2.82 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Get input shape and number of classes\n",
        "input_shape = X_train.shape[1:]\n",
        "\n",
        "# Convert y_train to a flat list of unique integers\n",
        "unique_labels = set()\n",
        "\n",
        "for tensor in y_train:\n",
        "    unique_labels.update(tensor.numpy().flatten())  # Convert tensor to NumPy and add unique values\n",
        "\n",
        "num_classes = len(unique_labels)\n",
        "\n",
        "print(f\"Input Shape: {input_shape}\")\n",
        "print(f\"Number of Classes: {num_classes}\")\n",
        "\n",
        "# Create CNN Model\n",
        "cnn_model = create_cnn_model(input_shape, num_classes)\n",
        "print(\"CNN Model Summary:\")\n",
        "cnn_model.summary()\n",
        "\n",
        "# Create CLDNN Model\n",
        "cldnn_model = create_cldnn_model(input_shape, num_classes)\n",
        "print(\"\\nCLDNN Model Summary:\")\n",
        "cldnn_model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgA15h8SbJVg"
      },
      "source": [
        "# **Step 4: Model Compilation and Training**\n",
        "\n",
        "We’ll now:\n",
        "\n",
        "* Compile the models with the CTC loss.\n",
        "* Set up an optimizer (Adam) and learning rate scheduler as described in the paper.\n",
        "* Train the models with early stopping based on validation loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNP3Hy5dxU-_"
      },
      "source": [
        "## **Step 4.1: Preprocessing and Loss Function Definition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbbQ90Xfa1z7",
        "outputId": "77cb87fc-76e5-4373-94d6-60d5ef35170f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Length Shape: (79,)\n",
            "Label Length Shape: (79,)\n"
          ]
        }
      ],
      "source": [
        "# Reshape X_train and X_test to ensure they match the model input shape\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
        "\n",
        "# Define lengths\n",
        "input_length = np.full((len(X_train),), X_train.shape[1], dtype=np.int32)  # All inputs have the same time steps\n",
        "label_length = np.array([len(label) for label in y_train])  # Actual label lengths\n",
        "\n",
        "print(f\"Input Length Shape: {input_length.shape}\")\n",
        "print(f\"Label Length Shape: {label_length.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuvchd0bivZa",
        "outputId": "c2cd3b5d-763a-4f55-e839-fbcb6bd2e8b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Label Length:  7\n",
            "y_train_padded shape: (79, 7)\n",
            "y_test_padded shape: (79, 7)\n"
          ]
        }
      ],
      "source": [
        "# Ensure labels are padded\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "print(\"Max Label Length: \", max_label_length)\n",
        "\n",
        "y_train_padded = pad_sequences(y_train, maxlen=max_label_length, padding=\"post\", value=0)\n",
        "y_test_padded = pad_sequences(y_test, maxlen=max_label_length, padding=\"post\", value=0)\n",
        "\n",
        "print(f\"y_train_padded shape: {y_train_padded.shape}\")\n",
        "print(f\"y_test_padded shape: {y_test_padded.shape}\")\n",
        "\n",
        "# Update the dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train_padded, input_length, label_length))\n",
        "train_dataset = train_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test_padded, input_length, label_length))\n",
        "val_dataset = val_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in y_train_padded:\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iv3J4y7wGUXN",
        "outputId": "95ec72d2-f04c-4859-c885-6450c00bc5d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5 0 0 0 0 0 0]\n",
            "[10  0  0  0  0  0  0]\n",
            "[31  0  0  0  0  0  0]\n",
            "[16  0  0  0  0  0  0]\n",
            "[36  0  0  0  0  0  0]\n",
            "[23  0  0  0  0  0  0]\n",
            "[17  0  0  0  0  0  0]\n",
            "[26  0  0  0  0  0  0]\n",
            "[52  0  0  0  0  0  0]\n",
            "[25  0  0  0  0  0  0]\n",
            "[28  0  0  0  0  0  0]\n",
            "[11  0  0  0  0  0  0]\n",
            "[32  0  0  0  0  0  0]\n",
            "[59  0  0  0  0  0  0]\n",
            "[39  0  0  0  0  0  0]\n",
            "[51  0  0  0  0  0  0]\n",
            "[46  0  0  0  0  0  0]\n",
            "[49  0  0  0  0  0  0]\n",
            "[33  0  0  0  0  0  0]\n",
            "[6 0 0 0 0 0 0]\n",
            "[2 0 0 0 0 0 0]\n",
            "[13  0  0  0  0  0  0]\n",
            "[37  0  0  0  0  0  0]\n",
            "[43  0  0  0  0  0  0]\n",
            "[54  0  0  0  0  0  0]\n",
            "[44  0  0  0  0  0  0]\n",
            "[19  0  0  0  0  0  0]\n",
            "[45  0  0  0  0  0  0]\n",
            "[40  0  0  0  0  0  0]\n",
            "[41  0  0  0  0  0  0]\n",
            "[4 0 0 0 0 0 0]\n",
            "[30  0  0  0  0  0  0]\n",
            "[38  0  0  0  0  0  0]\n",
            "[34  0  0  0  0  0  0]\n",
            "[53  0  0  0  0  0  0]\n",
            "[58  0  0  0  0  0  0]\n",
            "[62  0  0  0  0  0  0]\n",
            "[9 0 0 0 0 0 0]\n",
            "[12  0  0  0  0  0  0]\n",
            "[18  0  0  0  0  0  0]\n",
            "[47  0  0  0  0  0  0]\n",
            "[55  0  0  0  0  0  0]\n",
            "[20  0  0  0  0  0  0]\n",
            "[42  0  0  0  0  0  0]\n",
            "[29  0  0  0  0  0  0]\n",
            "[22  0  0  0  0  0  0]\n",
            "[56  0  0  0  0  0  0]\n",
            "[57  0  0  0  0  0  0]\n",
            "[7 0 0 0 0 0 0]\n",
            "[3 0 0 0 0 0 0]\n",
            "[8 0 0 0 0 0 0]\n",
            "[61  0  0  0  0  0  0]\n",
            "[60  0  0  0  0  0  0]\n",
            "[24  0  0  0  0  0  0]\n",
            "[15  0  0  0  0  0  0]\n",
            "[1 0 0 0 0 0 0]\n",
            "[27  0  0  0  0  0  0]\n",
            "[48  0  0  0  0  0  0]\n",
            "[35  0  0  0  0  0  0]\n",
            "[21  0  0  0  0  0  0]\n",
            "[50  0  0  0  0  0  0]\n",
            "[14  0  0  0  0  0  0]\n",
            "[34 53  0  0  0  0  0]\n",
            "[12  8  0  0  0  0  0]\n",
            "[18 19 12  4  0  0  0]\n",
            "[53 29  0  0  0  0  0]\n",
            "[22 56 18 19  0  0  0]\n",
            "[19 18 41  0  0  0  0]\n",
            "[53  0  0  0  0  0  0]\n",
            "[19 12  0  0  0  0  0]\n",
            "[15  1  0  0  0  0  0]\n",
            "[ 8  4 19 42 29  0  0]\n",
            "[47  9 41  0  0  0  0]\n",
            "[22 34 53 29  0  0  0]\n",
            "[53 29  0  0  0  0  0]\n",
            "[47 56 42  0  0  0  0]\n",
            "[30 53 42 29 22  0  0]\n",
            "[ 7 47 42 41  0  0  0]\n",
            "[41 19 22 19 29  4 22]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkuCQvPjkr25"
      },
      "outputs": [],
      "source": [
        "def ctc_loss_fn(y_true, y_pred):\n",
        "    # Cast labels to int32\n",
        "    y_true = tf.cast(y_true, dtype=tf.int32)\n",
        "\n",
        "    # Input length: Number of time steps for each input\n",
        "    input_length = tf.fill([tf.shape(y_pred)[0]], tf.shape(y_pred)[1])\n",
        "\n",
        "    # Label length: Actual length of each label\n",
        "    label_length = tf.reduce_sum(tf.cast(tf.not_equal(y_true, 0), dtype=tf.int32), axis=1)\n",
        "\n",
        "    ''' # Print values\n",
        "    tf.print(\"\\n--- CTC Loss Debug ---\")\n",
        "    tf.print(\"y_true:\", y_true, summarize=-1)  # Print all elements\n",
        "    tf.print(\"y_pred (Softmax Output):\", y_pred, summarize=3)  # Print first few values\n",
        "    tf.print(\"Input length:\", input_length)\n",
        "    tf.print(\"Label length:\", label_length) '''\n",
        "\n",
        "    # Compute CTC loss\n",
        "    return tf.reduce_mean(\n",
        "        tf.nn.ctc_loss(\n",
        "            labels=y_true,\n",
        "            logits=y_pred,\n",
        "            label_length=label_length,\n",
        "            logit_length=input_length,\n",
        "            logits_time_major=False,\n",
        "            blank_index=-1,  # Use the last class as the blank label\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WjQxsPRmlZr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7136b36a-b62f-454d-90dc-50ebdd45d0cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset Simple Shape: <_MapDataset element_spec=(TensorSpec(shape=(None, 64, 11), dtype=tf.float32, name=None), TensorSpec(shape=(None, 7), dtype=tf.int32, name=None))>\n",
            "Val Dataset Simple Shape: <_MapDataset element_spec=(TensorSpec(shape=(None, 64, 11), dtype=tf.float32, name=None), TensorSpec(shape=(None, 7), dtype=tf.int32, name=None))>\n"
          ]
        }
      ],
      "source": [
        "# Map dataset to (x, y)\n",
        "train_dataset_simple = train_dataset.map(lambda x, y, il, ll: (x, y))\n",
        "val_dataset_simple = val_dataset.map(lambda x, y, il, ll: (x, y))\n",
        "\n",
        "print(f\"Train Dataset Simple Shape: {train_dataset_simple}\")\n",
        "print(f\"Val Dataset Simple Shape: {val_dataset_simple}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0Kl9KwEsmRl"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=5, min_lr=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uid9zUi1gg_8",
        "outputId": "35065a28-7922-4ca6-df23-34fe1595e90e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 695ms/step - loss: 28.5476 - val_loss: 28.5738 - learning_rate: 0.0100\n",
            "Epoch 2/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 25.4374 - val_loss: 28.3304 - learning_rate: 0.0100\n",
            "Epoch 3/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 24.9235 - val_loss: 27.1554 - learning_rate: 0.0100\n",
            "Epoch 4/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 24.4367 - val_loss: 25.6635 - learning_rate: 0.0100\n",
            "Epoch 5/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 24.2870 - val_loss: 24.5983 - learning_rate: 0.0100\n",
            "Epoch 6/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 24.0190 - val_loss: 23.7083 - learning_rate: 0.0100\n",
            "Epoch 7/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 23.5200 - val_loss: 23.6089 - learning_rate: 0.0100\n",
            "Epoch 8/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 23.5091 - val_loss: 23.5797 - learning_rate: 0.0100\n",
            "Epoch 9/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 23.5078 - val_loss: 23.5716 - learning_rate: 0.0100\n",
            "Epoch 10/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 23.5075 - val_loss: 23.5693 - learning_rate: 0.0100\n",
            "Epoch 11/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 23.5073 - val_loss: 23.5686 - learning_rate: 0.0100\n",
            "Epoch 12/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 23.5073 - val_loss: 23.5684 - learning_rate: 0.0100\n",
            "Epoch 13/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 23.5072 - val_loss: 23.5683 - learning_rate: 0.0100\n",
            "Epoch 14/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 23.5072 - val_loss: 23.5683 - learning_rate: 0.0100\n",
            "Epoch 15/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 23.5072 - val_loss: 23.5683 - learning_rate: 0.0100\n",
            "Epoch 16/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 23.5072 - val_loss: 23.5683 - learning_rate: 0.0100\n",
            "Epoch 17/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 23.5072 - val_loss: 23.5683 - learning_rate: 0.0100\n",
            "Epoch 18/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 23.5072 - val_loss: 23.5683 - learning_rate: 0.0100\n",
            "Epoch 19/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 23.5072 - val_loss: 23.5683 - learning_rate: 0.0100\n",
            "Epoch 20/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 23.5072 - val_loss: 23.5683 - learning_rate: 0.0080\n",
            "Epoch 21/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 23.5072 - val_loss: 23.5683 - learning_rate: 0.0080\n",
            "Epoch 22/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 23.5072 - val_loss: 23.5683 - learning_rate: 0.0080\n",
            "Epoch 23/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 23.5072 - val_loss: 23.5683 - learning_rate: 0.0080\n",
            "Epoch 24/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 23.5072 - val_loss: 23.5683 - learning_rate: 0.0080\n",
            "Epoch 25/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 23.5072 - val_loss: 23.5683 - learning_rate: 0.0064\n",
            "Epoch 26/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 23.5072 - val_loss: 23.5683 - learning_rate: 0.0064\n",
            "Epoch 27/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 23.5072 - val_loss: 23.5683 - learning_rate: 0.0064\n",
            "Epoch 28/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 23.5072 - val_loss: 23.5683 - learning_rate: 0.0064\n",
            "Epoch 29/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 23.5072 - val_loss: 23.5683 - learning_rate: 0.0064\n",
            "Epoch 30/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 23.5072 - val_loss: 23.5683 - learning_rate: 0.0051\n",
            "Epoch 31/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 23.5072 - val_loss: 23.5683 - learning_rate: 0.0051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "cnn_model.compile(optimizer=Adam(learning_rate=0.01), loss=ctc_loss_fn)\n",
        "\n",
        "cnn_history = cnn_model.fit(\n",
        "    train_dataset_simple,\n",
        "    validation_data=val_dataset_simple,\n",
        "    epochs=50,\n",
        "    callbacks=[early_stopping, reduce_lr],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "cnn_model.save(\"cnn_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot loss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(cnn_history.history['loss'], label='Training Loss')\n",
        "plt.plot(cnn_history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "7J7kygkvjiNX",
        "outputId": "c8fa5a91-8d7c-4e75-e98d-bea61c6dcab4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQIeXxQxisAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fbbad6c-ebac-4f96-9c50-72e44a61f5c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - loss: 28.6841 - val_loss: 24.1813 - learning_rate: 0.0100\n",
            "Epoch 2/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 23.7934 - val_loss: 23.5683 - learning_rate: 0.0100\n",
            "Epoch 3/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 23.5072 - val_loss: 23.5683 - learning_rate: 0.0100\n",
            "Epoch 4/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 23.5072 - val_loss: 23.5683 - learning_rate: 0.0100\n",
            "Epoch 5/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 23.5072 - val_loss: 23.5683 - learning_rate: 0.0100\n",
            "Epoch 6/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 23.5072 - val_loss: 23.5683 - learning_rate: 0.0100\n",
            "Epoch 7/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 23.5072 - val_loss: 23.5683 - learning_rate: 0.0100\n",
            "Epoch 8/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 23.5072 - val_loss: 23.5683 - learning_rate: 0.0080\n",
            "Epoch 9/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 23.5072 - val_loss: 23.5683 - learning_rate: 0.0080\n",
            "Epoch 10/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 23.5072 - val_loss: 23.5683 - learning_rate: 0.0080\n",
            "Epoch 11/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 23.5072 - val_loss: 23.5683 - learning_rate: 0.0080\n",
            "Epoch 12/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 23.5072 - val_loss: 23.5683 - learning_rate: 0.0080\n",
            "Epoch 13/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 23.5072 - val_loss: 23.5683 - learning_rate: 0.0064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "cldnn_model.compile(optimizer=Adam(learning_rate=0.01), loss=ctc_loss_fn)\n",
        "\n",
        "cldnn_history = cldnn_model.fit(\n",
        "    train_dataset_simple,\n",
        "    validation_data=val_dataset_simple,\n",
        "    epochs=50,\n",
        "    callbacks=[early_stopping, reduce_lr],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "cldnn_model.save(\"cldnn_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot loss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(cldnn_history.history['loss'], label='Training Loss')\n",
        "plt.plot(cldnn_history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "JEDTbfofjrw3",
        "outputId": "bdc8acda-a037-4131-9c88-d9b57984eb6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr6fnQcRtM-k"
      },
      "source": [
        "## **Step 4.2: Decoding**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions for a sequence (CNN)\n",
        "\n",
        "# Get the prediction model by extracting layers till the output layer\n",
        "prediction_model = tf.keras.Model(\n",
        "    inputs=cnn_model.get_layer(name='Conv1').input,\n",
        "    outputs=Activation('softmax')(cnn_model.get_layer(name='Time1').output),\n",
        "    name='prediction_model'\n",
        ")\n",
        "prediction_model.summary()\n",
        "prediction_model.compile(optimizer=Adam(learning_rate=0.01), loss=ctc_loss_fn)\n",
        "\n",
        "# A utility function to decode the output of the network\n",
        "def decode_batch_predictions(pred):\n",
        "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
        "    # Use greedy search. For complex tasks, you can use beam search\n",
        "    results = tf.keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][\n",
        "        :, :max_length\n",
        "    ]\n",
        "    # Iterate over the results and get back the text\n",
        "    output_text = []\n",
        "    for res in results:\n",
        "        ''' print(\"res: \", res) '''\n",
        "        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n",
        "        output_text.append(res)\n",
        "        ''' print(\"output_text: \", output_text) '''\n",
        "    return output_text\n",
        "\n",
        "#  Let's check results on some samples\n",
        "for batch in val_dataset.take(1):\n",
        "    batch_sequences = batch[0]\n",
        "    batch_labels = batch[1]\n",
        "\n",
        "    preds = prediction_model.predict(batch_sequences)\n",
        "    for pred in preds[0:3]:\n",
        "        print(pred)\n",
        "    pred_texts = decode_batch_predictions(preds)\n",
        "\n",
        "    orig_texts = []\n",
        "    for label in batch_labels:\n",
        "        label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
        "        orig_texts.append(label)\n",
        "\n",
        "    for i in range(len(pred_texts)):\n",
        "      actual_text = orig_texts[i]\n",
        "      predicted_text = pred_texts[i]\n",
        "\n",
        "      # Remove [UNK]\n",
        "      actual_text = actual_text.replace(\"[UNK]\", \"\")\n",
        "      predicted_text = predicted_text.replace(\"[UNK]\", \"\")\n",
        "\n",
        "      if len(predicted_text) > 0:\n",
        "        print(\"actual text: \", actual_text)\n",
        "        print(\"predicted text: \", predicted_text)\n",
        "\n",
        "for batch in val_dataset.take(2):\n",
        "    batch_sequences = batch[0]\n",
        "    batch_labels = batch[1]\n",
        "\n",
        "    preds = prediction_model.predict(batch_sequences)\n",
        "    pred_texts = decode_batch_predictions(preds)\n",
        "\n",
        "    orig_texts = []\n",
        "    for label in batch_labels:\n",
        "        label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
        "        orig_texts.append(label)\n",
        "\n",
        "    for i in range(len(pred_texts)):\n",
        "      actual_text = orig_texts[i]\n",
        "      predicted_text = pred_texts[i]\n",
        "\n",
        "      # Remove [UNK]\n",
        "      actual_text = actual_text.replace(\"[UNK]\", \"\")\n",
        "      predicted_text = predicted_text.replace(\"[UNK]\", \"\")\n",
        "\n",
        "      if len(predicted_text) > 0:\n",
        "        print(\"actual text: \", actual_text)\n",
        "        print(\"predicted text: \", predicted_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RRObWhFjb1zO",
        "outputId": "27b913f2-b643-4764-d14d-b0676172baeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"prediction_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"prediction_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequence (\u001b[38;5;33mInputLayer\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m11\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1 (\u001b[38;5;33mConv1D\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1024\u001b[0m)            │          \u001b[38;5;34m57,344\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_112              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1024\u001b[0m)            │           \u001b[38;5;34m4,096\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_112 (\u001b[38;5;33mReLU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1024\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_109 (\u001b[38;5;33mMaxPooling1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_144 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv2 (\u001b[38;5;33mConv1D\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │       \u001b[38;5;34m1,573,376\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_113              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_113 (\u001b[38;5;33mReLU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_110 (\u001b[38;5;33mMaxPooling1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_145 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv3 (\u001b[38;5;33mConv1D\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │         \u001b[38;5;34m393,472\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_114              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_114 (\u001b[38;5;33mReLU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_111 (\u001b[38;5;33mMaxPooling1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_146 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Time1 (\u001b[38;5;33mTimeDistributed\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m62\u001b[0m)               │          \u001b[38;5;34m15,934\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_23 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m62\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequence (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">57,344</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_112              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_112 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_109 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_144 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,573,376</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_113              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_113 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_110 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_145 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">393,472</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_114              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_114 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_111 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_146 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Time1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">15,934</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,047,294\u001b[0m (7.81 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,047,294</span> (7.81 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,043,710\u001b[0m (7.80 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,043,710</span> (7.80 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,584\u001b[0m (14.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,584</span> (14.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step \n",
            "[[7.14792940e-24 1.49456704e-22 9.44180739e-23 1.68634702e-21\n",
            "  3.94424023e-24 6.37878056e-24 3.64424994e-25 1.20285776e-22\n",
            "  4.77529928e-24 5.57470016e-23 1.90407697e-22 5.17533627e-25\n",
            "  2.12101085e-21 2.03207217e-24 7.25092368e-22 7.77699533e-23\n",
            "  1.07697872e-26 3.74806078e-24 5.66233755e-23 1.68380707e-22\n",
            "  5.30215805e-22 3.91998370e-25 1.70613309e-22 3.45744743e-25\n",
            "  5.32556250e-25 1.85366409e-23 3.48493677e-25 8.94938400e-24\n",
            "  4.69909305e-25 1.04114501e-23 1.06434794e-23 2.03917174e-22\n",
            "  4.20102965e-22 6.97942225e-23 1.06740257e-21 6.90207735e-25\n",
            "  2.03244635e-22 7.89000455e-24 1.28525561e-22 1.38993063e-23\n",
            "  1.17450394e-24 1.35865967e-24 4.90228439e-25 6.38039283e-22\n",
            "  1.09771400e-25 7.57689619e-24 1.55220048e-24 2.25482400e-23\n",
            "  5.58811332e-23 2.81652137e-24 1.01024904e-22 1.04935533e-22\n",
            "  3.59196062e-22 3.70114983e-22 4.59456849e-24 1.08660844e-22\n",
            "  6.21786200e-24 2.28070574e-24 5.19285502e-26 5.08733400e-24\n",
            "  1.03020146e-23 9.99999940e-01]\n",
            " [2.94127693e-19 5.96728135e-18 3.91045375e-18 3.19565348e-17\n",
            "  3.04370929e-19 5.57413699e-19 5.18572451e-20 4.95471757e-18\n",
            "  3.80199998e-19 1.43364514e-18 4.74643721e-18 1.37108586e-19\n",
            "  7.06723925e-17 1.79741798e-19 1.72969620e-17 2.56769042e-18\n",
            "  3.19121292e-21 2.53142212e-19 1.99132276e-18 6.28191811e-18\n",
            "  1.09429014e-17 2.51453035e-20 9.77344582e-18 3.62618985e-20\n",
            "  5.38112169e-20 9.30278646e-19 2.76074405e-20 4.26470284e-19\n",
            "  8.48742238e-20 5.40035151e-19 4.67700326e-19 3.22015085e-18\n",
            "  1.73586333e-17 3.28986894e-18 2.19847600e-17 6.19793444e-20\n",
            "  1.06561054e-17 2.90778646e-19 5.06823115e-18 4.69097641e-19\n",
            "  7.81918840e-20 7.80592637e-20 6.88051160e-20 1.23560658e-17\n",
            "  1.73357782e-20 4.51333317e-19 2.16007580e-19 1.37180853e-18\n",
            "  1.39042206e-18 1.47961027e-19 3.66737059e-18 2.01051190e-18\n",
            "  1.09911798e-17 3.47619923e-18 3.57431981e-19 1.86081020e-18\n",
            "  9.47928613e-19 8.04517673e-20 9.44938335e-21 2.98897475e-19\n",
            "  4.25157807e-19 9.99999940e-01]\n",
            " [6.72568368e-22 2.13289022e-20 6.53147911e-21 1.16970925e-19\n",
            "  1.62319769e-22 6.05301429e-22 2.50793700e-22 7.28088980e-21\n",
            "  7.39768766e-22 1.06856367e-21 2.02293433e-20 1.13499161e-22\n",
            "  1.43948064e-19 2.38303293e-22 1.72496917e-20 6.32799146e-21\n",
            "  1.18276331e-24 2.71166430e-22 6.05262473e-21 2.94408185e-20\n",
            "  4.14963588e-20 2.06794333e-23 5.53470231e-20 1.45517968e-23\n",
            "  9.40273731e-23 9.11115514e-22 5.18367948e-23 8.85309539e-22\n",
            "  5.86879381e-23 2.33226664e-21 4.41967034e-22 7.43696440e-21\n",
            "  2.58127009e-20 1.66813233e-20 1.37625793e-19 1.60664473e-22\n",
            "  3.37626918e-20 5.35059689e-22 1.37757027e-20 7.39602310e-22\n",
            "  1.94450755e-22 1.50663396e-22 8.05748082e-23 1.10999185e-19\n",
            "  1.89734742e-23 4.28614307e-22 3.07175722e-22 4.75202822e-21\n",
            "  1.69680694e-21 3.10304988e-22 3.04551806e-21 5.00984563e-21\n",
            "  2.45455782e-20 8.41356501e-21 3.63460657e-22 2.56501377e-21\n",
            "  5.49567056e-22 1.55399717e-22 1.65403748e-23 3.36143578e-22\n",
            "  6.09509175e-22 9.99999940e-01]\n",
            " [1.20603967e-18 1.83280079e-17 1.80097502e-17 3.39443160e-17\n",
            "  2.04208704e-18 8.02424699e-19 1.31607292e-19 5.53318855e-18\n",
            "  2.98323515e-18 1.34890402e-17 1.02580066e-17 1.16764066e-19\n",
            "  4.39188304e-17 8.07349629e-19 1.06290730e-16 1.39000903e-17\n",
            "  9.09452691e-21 9.45534235e-19 7.87051848e-18 8.72620539e-18\n",
            "  3.41463962e-17 9.81464531e-20 9.69657427e-18 3.66886629e-19\n",
            "  1.40281340e-19 2.57683553e-18 2.17741596e-19 1.19669987e-18\n",
            "  7.69355970e-20 1.79084851e-18 1.64135143e-18 3.08458761e-17\n",
            "  2.46734758e-17 5.35785852e-18 2.97631397e-17 2.12143380e-19\n",
            "  1.46119156e-17 2.86156040e-18 1.18072985e-17 1.26612400e-18\n",
            "  5.13670320e-19 3.01708674e-19 1.06619910e-19 3.55033860e-17\n",
            "  4.15563972e-20 1.51580878e-18 7.31848926e-19 2.45107016e-18\n",
            "  2.36753443e-18 7.64604865e-19 1.03856968e-17 9.35992334e-18\n",
            "  5.52412257e-17 1.00195064e-16 5.11804356e-19 1.83627197e-17\n",
            "  6.13768221e-19 1.04024238e-18 2.83200889e-20 6.78493760e-19\n",
            "  1.93288555e-18 9.99999940e-01]\n",
            " [6.99704783e-09 3.51373619e-09 1.32209248e-08 1.37727305e-08\n",
            "  6.05228800e-09 8.32243996e-10 1.30988320e-09 1.35422225e-08\n",
            "  6.30861097e-09 1.89287483e-08 6.41469500e-09 1.62496061e-09\n",
            "  2.64217963e-08 3.10902792e-09 2.32137172e-08 7.93327803e-09\n",
            "  7.57697405e-10 3.41391537e-09 6.58161170e-09 1.63734395e-08\n",
            "  7.63826957e-09 1.89905403e-09 1.50519011e-08 1.91437932e-09\n",
            "  2.93378766e-09 6.07474737e-09 3.19526827e-09 5.97891381e-09\n",
            "  1.02554210e-09 5.05021580e-09 9.35760447e-09 1.39697276e-08\n",
            "  9.28515487e-09 5.05267250e-09 1.80905886e-08 3.74026010e-09\n",
            "  8.11314305e-09 5.21288257e-09 1.08015188e-08 8.25796231e-09\n",
            "  3.13181103e-09 2.75746337e-09 1.07797382e-09 4.64031977e-08\n",
            "  1.49346457e-09 5.45043921e-09 4.46805171e-09 4.76288875e-09\n",
            "  3.75568687e-09 7.13893211e-09 6.17724094e-09 7.25002591e-09\n",
            "  3.97677482e-08 2.01546499e-07 6.31929009e-10 1.10348086e-08\n",
            "  3.57653840e-09 2.03037787e-09 1.40960799e-09 2.31912245e-09\n",
            "  6.29845109e-09 9.99999225e-01]\n",
            " [9.00347974e-09 4.52625848e-09 1.69833214e-08 1.77714341e-08\n",
            "  7.85224064e-09 1.09290454e-09 1.74130743e-09 1.75063946e-08\n",
            "  8.22308444e-09 2.40428228e-08 8.31736546e-09 2.12472284e-09\n",
            "  3.33351089e-08 4.03500078e-09 2.90620346e-08 1.01555679e-08\n",
            "  1.00924380e-09 4.41103021e-09 8.47125747e-09 2.11824958e-08\n",
            "  9.76027525e-09 2.48435139e-09 1.92054621e-08 2.49095611e-09\n",
            "  3.87007404e-09 7.77256570e-09 4.19947588e-09 7.82322385e-09\n",
            "  1.36707556e-09 6.57571331e-09 1.20784041e-08 1.77057302e-08\n",
            "  1.17607044e-08 6.62160149e-09 2.33840023e-08 4.90802732e-09\n",
            "  1.03840732e-08 6.76696299e-09 1.39335086e-08 1.07262732e-08\n",
            "  4.10979162e-09 3.60721608e-09 1.42610157e-09 5.93680198e-08\n",
            "  1.99758454e-09 6.99335123e-09 5.84140292e-09 6.22050145e-09\n",
            "  4.90222662e-09 9.37141031e-09 8.01889577e-09 9.40010736e-09\n",
            "  5.01957302e-08 2.55424794e-07 8.33562497e-10 1.40490863e-08\n",
            "  4.68497019e-09 2.67008726e-09 1.87133131e-09 3.04425662e-09\n",
            "  8.06194400e-09 9.99999106e-01]\n",
            " [9.00347974e-09 4.52625848e-09 1.69833214e-08 1.77714341e-08\n",
            "  7.85224064e-09 1.09290454e-09 1.74130743e-09 1.75063946e-08\n",
            "  8.22308444e-09 2.40428228e-08 8.31736546e-09 2.12472284e-09\n",
            "  3.33351089e-08 4.03500078e-09 2.90620346e-08 1.01555679e-08\n",
            "  1.00924380e-09 4.41103021e-09 8.47125747e-09 2.11824958e-08\n",
            "  9.76027525e-09 2.48435139e-09 1.92054621e-08 2.49095611e-09\n",
            "  3.87007404e-09 7.77256570e-09 4.19947588e-09 7.82322385e-09\n",
            "  1.36707556e-09 6.57571331e-09 1.20784041e-08 1.77057302e-08\n",
            "  1.17607044e-08 6.62160149e-09 2.33840023e-08 4.90802732e-09\n",
            "  1.03840732e-08 6.76696299e-09 1.39335086e-08 1.07262732e-08\n",
            "  4.10979162e-09 3.60721608e-09 1.42610157e-09 5.93680198e-08\n",
            "  1.99758454e-09 6.99335123e-09 5.84140292e-09 6.22050145e-09\n",
            "  4.90222662e-09 9.37141031e-09 8.01889577e-09 9.40010736e-09\n",
            "  5.01957302e-08 2.55424794e-07 8.33562497e-10 1.40490863e-08\n",
            "  4.68497019e-09 2.67008726e-09 1.87133131e-09 3.04425662e-09\n",
            "  8.06194400e-09 9.99999106e-01]\n",
            " [1.07394382e-09 5.35026190e-10 2.35936781e-09 2.36346209e-09\n",
            "  8.00996991e-10 9.21855300e-11 1.54521063e-10 2.31439556e-09\n",
            "  8.74016581e-10 2.97594016e-09 7.83451415e-10 1.77018414e-10\n",
            "  4.75814277e-09 3.17111060e-10 3.88785537e-09 9.36290712e-10\n",
            "  8.88993115e-11 4.14573265e-10 8.58325411e-10 2.63932920e-09\n",
            "  1.01103637e-09 1.94660454e-10 2.05720596e-09 2.25796742e-10\n",
            "  3.51042057e-10 8.96595131e-10 3.38185480e-10 7.90352506e-10\n",
            "  1.21862104e-10 6.49496679e-10 1.34755418e-09 2.11672746e-09\n",
            "  1.29133593e-09 6.94716729e-10 2.96078384e-09 4.82346496e-10\n",
            "  1.03056630e-09 6.75841272e-10 1.57747704e-09 1.28270494e-09\n",
            "  3.50083240e-10 3.65214026e-10 1.36216691e-10 5.90041971e-09\n",
            "  1.50799997e-10 7.82070408e-10 4.56100213e-10 5.79678638e-10\n",
            "  5.22540622e-10 1.06849474e-09 9.61519087e-10 9.33795707e-10\n",
            "  7.19583326e-09 3.96454638e-08 6.47593715e-11 1.80359472e-09\n",
            "  4.12815226e-10 2.02482420e-10 1.75633799e-10 3.01910358e-10\n",
            "  1.08363518e-09 9.99999821e-01]]\n",
            "[[4.92237490e-24 6.70572348e-23 6.49683185e-23 9.44148717e-22\n",
            "  3.69823869e-24 3.12615578e-24 1.45465088e-25 5.93459933e-23\n",
            "  2.59549299e-24 3.89598648e-23 8.14120989e-23 2.44913602e-25\n",
            "  1.13052416e-21 9.44954390e-25 5.11830878e-22 3.58795996e-23\n",
            "  6.29085834e-27 1.86281456e-24 2.51891397e-23 6.21125032e-23\n",
            "  2.51289761e-22 2.32455221e-25 4.11882927e-23 2.21135289e-25\n",
            "  2.81829334e-25 1.31795938e-23 1.69526381e-25 4.19044569e-24\n",
            "  2.57943267e-25 3.82890167e-24 6.66494143e-24 1.20991257e-22\n",
            "  2.49756871e-22 3.13596317e-23 5.34327424e-22 4.18603369e-25\n",
            "  7.92923286e-23 4.45110230e-24 7.13189076e-23 1.09724209e-23\n",
            "  7.05934318e-25 8.15904684e-25 2.48222529e-25 2.65617444e-22\n",
            "  5.21061425e-26 4.27068310e-24 7.81797543e-25 8.33633495e-24\n",
            "  3.26544175e-23 2.10122884e-24 5.20909216e-23 5.39721024e-23\n",
            "  2.09011095e-22 2.43206499e-22 2.07716878e-24 8.80570214e-23\n",
            "  3.34290340e-24 1.05491706e-24 2.47455651e-26 2.34267786e-24\n",
            "  6.73232514e-24 9.99999940e-01]\n",
            " [9.35518857e-23 8.08448637e-22 9.60950520e-22 1.37473023e-20\n",
            "  7.28388280e-23 8.54455194e-23 5.35571710e-24 1.50968388e-21\n",
            "  5.82745561e-23 2.83893925e-22 6.45880535e-22 2.04830006e-23\n",
            "  5.20145516e-20 1.63304715e-23 4.70107502e-21 3.68909805e-22\n",
            "  2.33997937e-25 3.27802219e-23 3.25265072e-22 1.32160571e-21\n",
            "  2.41972140e-21 3.22573507e-24 1.65684943e-21 2.80170143e-24\n",
            "  6.43661353e-24 2.27192900e-22 2.70915957e-24 4.94056895e-23\n",
            "  1.25783587e-23 6.02504381e-23 9.15683044e-23 6.71676110e-22\n",
            "  7.43997181e-21 8.02414318e-22 8.98137442e-21 1.59784250e-23\n",
            "  1.50034306e-21 3.25632378e-23 1.10785455e-21 1.58452002e-22\n",
            "  1.30583853e-23 1.19800314e-23 8.43305718e-24 2.61190518e-21\n",
            "  1.35522261e-24 6.72801543e-23 2.20568523e-23 1.25898856e-22\n",
            "  3.37281607e-22 2.93864666e-23 5.96360518e-22 4.61315356e-22\n",
            "  2.90907062e-21 7.81780898e-22 2.57986830e-23 6.87872068e-22\n",
            "  1.76194431e-22 5.51717445e-24 8.90099863e-25 3.20986524e-23\n",
            "  8.83143667e-23 9.99999940e-01]\n",
            " [1.39038659e-23 1.12561843e-21 2.20678878e-22 2.61514524e-21\n",
            "  1.59615433e-24 1.89621872e-23 5.45558137e-24 1.76278467e-22\n",
            "  1.83213813e-23 1.63425616e-23 6.51980033e-22 3.29885696e-24\n",
            "  7.04671206e-21 7.16244997e-24 3.96957281e-22 2.29083137e-22\n",
            "  1.37085090e-26 6.85838116e-24 2.27000595e-22 1.10794754e-21\n",
            "  1.58352995e-21 1.49123899e-25 3.32800893e-21 3.01499507e-25\n",
            "  1.00677781e-24 1.34401009e-23 1.19495368e-24 1.59476736e-23\n",
            "  6.47011438e-25 1.53175003e-22 5.61938479e-24 1.07721923e-22\n",
            "  8.45861495e-22 6.76476878e-22 7.39825574e-21 2.19934065e-24\n",
            "  1.15717923e-21 8.05062530e-24 3.20334704e-22 1.13747897e-23\n",
            "  4.16489922e-24 2.10516821e-24 2.92889756e-24 3.16379499e-21\n",
            "  2.20654133e-25 7.73282401e-24 6.60732579e-24 1.83390117e-22\n",
            "  2.73008603e-23 4.10934803e-24 6.78339662e-23 9.78532160e-23\n",
            "  1.09868397e-21 1.48944461e-22 8.09447572e-24 3.70740770e-23\n",
            "  1.06822030e-23 2.53740049e-24 2.75820039e-25 5.71412974e-24\n",
            "  8.22288649e-24 9.99999940e-01]\n",
            " [9.61699567e-20 2.12578490e-18 1.82776579e-18 3.11644907e-18\n",
            "  1.71283940e-19 7.06757914e-20 9.26463612e-21 4.95492302e-19\n",
            "  2.75796673e-19 1.26138033e-18 9.29884805e-19 8.36163600e-21\n",
            "  4.62385732e-18 6.59137773e-20 1.15892214e-17 1.43362332e-18\n",
            "  5.43433833e-22 8.15194313e-20 7.68470538e-19 8.54600357e-19\n",
            "  3.57399431e-18 6.18697090e-21 9.24177259e-19 3.08124293e-20\n",
            "  8.88805568e-21 2.08434948e-19 1.64160019e-20 9.41624734e-20\n",
            "  4.67607099e-21 1.60666547e-19 1.21341799e-19 3.05428355e-18\n",
            "  2.70385056e-18 4.90665807e-19 3.07738133e-18 1.48691418e-20\n",
            "  1.37237380e-18 2.41863475e-19 1.15028884e-18 9.38812837e-20\n",
            "  4.21937496e-20 2.07127027e-20 7.92600505e-21 3.22937680e-18\n",
            "  2.62169786e-21 1.18774877e-19 5.75485062e-20 2.28117259e-19\n",
            "  1.98667083e-19 5.57498472e-20 9.71422920e-19 8.49066519e-19\n",
            "  5.77253409e-18 9.70064400e-18 4.30325139e-20 1.74820942e-18\n",
            "  4.76021343e-20 8.69645480e-20 1.73355690e-21 5.57898426e-20\n",
            "  1.43964543e-19 9.99999940e-01]\n",
            " [6.70001388e-09 3.36488148e-09 1.26718076e-08 1.31902231e-08\n",
            "  5.78951553e-09 7.94484367e-10 1.24836508e-09 1.29680053e-08\n",
            "  6.03230488e-09 1.81719990e-08 6.13646911e-09 1.55270286e-09\n",
            "  2.53788421e-08 2.97478087e-09 2.23363408e-08 7.60561836e-09\n",
            "  7.21362192e-10 3.26750649e-09 6.30087937e-09 1.56682898e-08\n",
            "  7.32698613e-09 1.81362547e-09 1.44326524e-08 1.82993587e-09\n",
            "  2.79980861e-09 5.82223869e-09 3.04964454e-09 5.71497649e-09\n",
            "  9.76882131e-10 4.82762541e-09 8.96333585e-09 1.34237226e-08\n",
            "  8.91969254e-09 4.82648366e-09 1.73285688e-08 3.57335428e-09\n",
            "  7.78390241e-09 4.98883823e-09 1.03455253e-08 7.90253107e-09\n",
            "  2.99012859e-09 2.63436384e-09 1.02811959e-09 4.45021904e-08\n",
            "  1.42171297e-09 5.22239718e-09 4.26985824e-09 4.54962024e-09\n",
            "  3.58881813e-09 6.82360390e-09 5.91097127e-09 6.93862612e-09\n",
            "  3.82242931e-08 1.93577307e-07 6.02880523e-10 1.05839151e-08\n",
            "  3.41669093e-09 1.93805438e-09 1.34348321e-09 2.21480123e-09\n",
            "  6.03946537e-09 9.99999344e-01]\n",
            " [9.00347974e-09 4.52625848e-09 1.69833214e-08 1.77714341e-08\n",
            "  7.85224064e-09 1.09290454e-09 1.74130743e-09 1.75063946e-08\n",
            "  8.22308444e-09 2.40428228e-08 8.31736546e-09 2.12472284e-09\n",
            "  3.33351089e-08 4.03500078e-09 2.90620346e-08 1.01555679e-08\n",
            "  1.00924380e-09 4.41103021e-09 8.47125747e-09 2.11824958e-08\n",
            "  9.76027525e-09 2.48435139e-09 1.92054621e-08 2.49095611e-09\n",
            "  3.87007404e-09 7.77256570e-09 4.19947588e-09 7.82322385e-09\n",
            "  1.36707556e-09 6.57571331e-09 1.20784041e-08 1.77057302e-08\n",
            "  1.17607044e-08 6.62160149e-09 2.33840023e-08 4.90802732e-09\n",
            "  1.03840732e-08 6.76696299e-09 1.39335086e-08 1.07262732e-08\n",
            "  4.10979162e-09 3.60721608e-09 1.42610157e-09 5.93680198e-08\n",
            "  1.99758454e-09 6.99335123e-09 5.84140292e-09 6.22050145e-09\n",
            "  4.90222662e-09 9.37141031e-09 8.01889577e-09 9.40010736e-09\n",
            "  5.01957302e-08 2.55424794e-07 8.33562497e-10 1.40490863e-08\n",
            "  4.68497019e-09 2.67008726e-09 1.87133131e-09 3.04425662e-09\n",
            "  8.06194400e-09 9.99999106e-01]\n",
            " [9.00347974e-09 4.52625848e-09 1.69833214e-08 1.77714341e-08\n",
            "  7.85224064e-09 1.09290454e-09 1.74130743e-09 1.75063946e-08\n",
            "  8.22308444e-09 2.40428228e-08 8.31736546e-09 2.12472284e-09\n",
            "  3.33351089e-08 4.03500078e-09 2.90620346e-08 1.01555679e-08\n",
            "  1.00924380e-09 4.41103021e-09 8.47125747e-09 2.11824958e-08\n",
            "  9.76027525e-09 2.48435139e-09 1.92054621e-08 2.49095611e-09\n",
            "  3.87007404e-09 7.77256570e-09 4.19947588e-09 7.82322385e-09\n",
            "  1.36707556e-09 6.57571331e-09 1.20784041e-08 1.77057302e-08\n",
            "  1.17607044e-08 6.62160149e-09 2.33840023e-08 4.90802732e-09\n",
            "  1.03840732e-08 6.76696299e-09 1.39335086e-08 1.07262732e-08\n",
            "  4.10979162e-09 3.60721608e-09 1.42610157e-09 5.93680198e-08\n",
            "  1.99758454e-09 6.99335123e-09 5.84140292e-09 6.22050145e-09\n",
            "  4.90222662e-09 9.37141031e-09 8.01889577e-09 9.40010736e-09\n",
            "  5.01957302e-08 2.55424794e-07 8.33562497e-10 1.40490863e-08\n",
            "  4.68497019e-09 2.67008726e-09 1.87133131e-09 3.04425662e-09\n",
            "  8.06194400e-09 9.99999106e-01]\n",
            " [1.07394382e-09 5.35026190e-10 2.35936781e-09 2.36346209e-09\n",
            "  8.00996991e-10 9.21855300e-11 1.54521063e-10 2.31439556e-09\n",
            "  8.74016581e-10 2.97594016e-09 7.83451415e-10 1.77018414e-10\n",
            "  4.75814277e-09 3.17111060e-10 3.88785537e-09 9.36290712e-10\n",
            "  8.88993115e-11 4.14573265e-10 8.58325411e-10 2.63932920e-09\n",
            "  1.01103637e-09 1.94660454e-10 2.05720596e-09 2.25796742e-10\n",
            "  3.51042057e-10 8.96595131e-10 3.38185480e-10 7.90352506e-10\n",
            "  1.21862104e-10 6.49496679e-10 1.34755418e-09 2.11672746e-09\n",
            "  1.29133593e-09 6.94716729e-10 2.96078384e-09 4.82346496e-10\n",
            "  1.03056630e-09 6.75841272e-10 1.57747704e-09 1.28270494e-09\n",
            "  3.50083240e-10 3.65214026e-10 1.36216691e-10 5.90041971e-09\n",
            "  1.50799997e-10 7.82070408e-10 4.56100213e-10 5.79678638e-10\n",
            "  5.22540622e-10 1.06849474e-09 9.61519087e-10 9.33795707e-10\n",
            "  7.19583326e-09 3.96454638e-08 6.47593715e-11 1.80359472e-09\n",
            "  4.12815226e-10 2.02482420e-10 1.75633799e-10 3.01910358e-10\n",
            "  1.08363518e-09 9.99999821e-01]]\n",
            "[[3.70594657e-18 1.11574108e-17 1.74988503e-17 2.06967101e-16\n",
            "  2.76317037e-18 2.86551474e-18 3.04317524e-19 3.21467830e-17\n",
            "  1.76559448e-18 8.79330380e-18 1.47678110e-17 4.33599521e-19\n",
            "  3.32263867e-16 6.03087407e-19 6.96266310e-17 5.54847030e-18\n",
            "  2.76009135e-20 1.57339834e-18 6.81503105e-18 2.17161166e-17\n",
            "  4.84127372e-17 3.06007790e-19 1.41961597e-17 1.13025351e-19\n",
            "  3.62244517e-19 6.26516605e-18 1.11538675e-19 2.14662985e-18\n",
            "  6.71695059e-19 1.29432114e-18 3.92234612e-18 2.60068562e-17\n",
            "  6.22626192e-17 1.49499843e-17 1.00858092e-16 8.53349402e-19\n",
            "  1.44965454e-17 1.19449233e-18 1.77134309e-17 5.02158189e-18\n",
            "  6.69474648e-19 6.05170713e-19 2.82586998e-19 3.97464354e-17\n",
            "  9.90480024e-20 1.70850071e-18 6.72823437e-19 3.02146496e-18\n",
            "  1.30560343e-17 1.68066598e-18 2.13705519e-17 1.36350351e-17\n",
            "  2.64557341e-17 2.72378019e-17 7.92380659e-19 1.81970371e-17\n",
            "  5.63247173e-18 3.76806903e-19 5.34270917e-20 1.54218933e-18\n",
            "  2.84713333e-18 9.99999940e-01]\n",
            " [2.86401683e-26 2.81811210e-24 5.39629916e-25 2.19598003e-23\n",
            "  6.32775454e-27 5.50201515e-26 1.69726213e-26 1.24844673e-24\n",
            "  4.17252815e-26 7.53322660e-26 2.02799868e-24 3.50566666e-27\n",
            "  1.54385112e-23 1.15277916e-26 2.55850173e-24 7.32338233e-25\n",
            "  2.19625814e-29 1.80260941e-26 8.87204842e-25 4.77549965e-24\n",
            "  8.06088917e-24 8.34911238e-28 1.39290290e-23 2.70898850e-28\n",
            "  5.14482063e-27 2.69850210e-26 1.63283210e-27 6.62288851e-26\n",
            "  2.29754679e-27 1.97535208e-25 1.79358266e-26 1.07586300e-24\n",
            "  2.59027054e-24 2.56183190e-24 2.20639204e-23 6.46685059e-27\n",
            "  4.48810106e-24 2.94437618e-26 1.15937339e-24 1.96345862e-26\n",
            "  9.92113922e-27 5.18066411e-27 4.28601727e-27 1.65233480e-23\n",
            "  7.00960837e-28 2.78461829e-26 1.27677469e-26 6.94692952e-25\n",
            "  1.25122079e-25 1.49608703e-26 7.51357127e-25 6.16620078e-25\n",
            "  2.19761305e-24 1.47794816e-24 2.21668944e-26 1.43461381e-25\n",
            "  3.14998600e-26 7.75541174e-27 5.07669933e-28 3.02666701e-26\n",
            "  3.71551483e-26 9.99999940e-01]\n",
            " [1.87229395e-27 5.10548954e-25 1.19983131e-25 1.10246506e-24\n",
            "  1.96249912e-27 3.42420984e-27 1.92440774e-28 4.98596300e-26\n",
            "  6.60948342e-27 4.03307603e-26 1.66013596e-25 1.34068846e-28\n",
            "  3.48506989e-25 1.53199147e-27 2.05393249e-24 1.55540037e-25\n",
            "  2.44402485e-30 1.80562981e-27 1.07743547e-25 1.50591340e-25\n",
            "  1.04048535e-24 5.49487494e-29 3.94120011e-25 2.16375220e-28\n",
            "  1.81268912e-28 4.40036281e-27 1.61948789e-28 4.09321165e-27\n",
            "  8.41096398e-29 1.35220019e-26 2.42677631e-27 2.63396219e-25\n",
            "  3.06317549e-25 7.02527598e-26 7.33694432e-25 1.25546931e-28\n",
            "  2.19336562e-25 1.20880292e-26 8.36742174e-26 2.31289183e-27\n",
            "  6.21021599e-28 2.32729013e-28 1.43420669e-28 9.94498306e-25\n",
            "  3.39258548e-29 3.13965542e-27 1.19785447e-27 2.92301223e-26\n",
            "  1.68191601e-26 1.43616201e-27 1.36953969e-25 1.15138662e-25\n",
            "  7.38876460e-25 1.42533587e-24 1.74087446e-27 3.89934069e-26\n",
            "  1.71963473e-27 2.48728421e-27 1.37476054e-29 2.41908645e-27\n",
            "  5.76117830e-27 9.99999940e-01]\n",
            " [1.14089727e-11 7.16391529e-12 2.95679072e-11 3.26353111e-11\n",
            "  1.05205870e-11 1.25689791e-12 1.22595662e-12 2.39986850e-11\n",
            "  1.11511477e-11 4.46198668e-11 1.14159385e-11 1.75386929e-12\n",
            "  7.47612805e-11 4.73914267e-12 7.12285370e-11 1.71210164e-11\n",
            "  5.31033930e-13 5.69402598e-12 1.16868598e-11 2.52632932e-11\n",
            "  1.97045921e-11 2.17763980e-12 2.44861648e-11 3.08271334e-12\n",
            "  2.83994486e-12 1.29684145e-11 3.44303210e-12 7.10067161e-12\n",
            "  8.47496444e-13 6.77996808e-12 1.60195347e-11 3.73888941e-11\n",
            "  2.46533245e-11 6.63117694e-12 4.46163766e-11 4.17118900e-12\n",
            "  1.63588136e-11 8.38547114e-12 2.58662432e-11 1.10344425e-11\n",
            "  3.89722673e-12 3.31296991e-12 9.60987800e-13 8.04394051e-11\n",
            "  9.73183990e-13 9.83184801e-12 5.83634313e-12 6.42430163e-12\n",
            "  5.51091854e-12 7.50920767e-12 1.05672441e-11 1.06434228e-11\n",
            "  1.15884448e-10 4.06247785e-10 8.31935432e-13 3.44827847e-11\n",
            "  3.96043441e-12 2.32973406e-12 1.09967851e-12 3.49213930e-12\n",
            "  1.12931869e-11 9.99999940e-01]\n",
            " [9.00347974e-09 4.52625848e-09 1.69833214e-08 1.77714341e-08\n",
            "  7.85224064e-09 1.09290454e-09 1.74130743e-09 1.75063946e-08\n",
            "  8.22308444e-09 2.40428228e-08 8.31736546e-09 2.12472284e-09\n",
            "  3.33351089e-08 4.03500078e-09 2.90620346e-08 1.01555679e-08\n",
            "  1.00924380e-09 4.41103021e-09 8.47125747e-09 2.11824958e-08\n",
            "  9.76027525e-09 2.48435139e-09 1.92054621e-08 2.49095611e-09\n",
            "  3.87007404e-09 7.77256570e-09 4.19947588e-09 7.82322385e-09\n",
            "  1.36707556e-09 6.57571331e-09 1.20784041e-08 1.77057302e-08\n",
            "  1.17607044e-08 6.62160149e-09 2.33840023e-08 4.90802732e-09\n",
            "  1.03840732e-08 6.76696299e-09 1.39335086e-08 1.07262732e-08\n",
            "  4.10979162e-09 3.60721608e-09 1.42610157e-09 5.93680198e-08\n",
            "  1.99758454e-09 6.99335123e-09 5.84140292e-09 6.22050145e-09\n",
            "  4.90222662e-09 9.37141031e-09 8.01889577e-09 9.40010736e-09\n",
            "  5.01957302e-08 2.55424794e-07 8.33562497e-10 1.40490863e-08\n",
            "  4.68497019e-09 2.67008726e-09 1.87133131e-09 3.04425662e-09\n",
            "  8.06194400e-09 9.99999106e-01]\n",
            " [9.00347974e-09 4.52625848e-09 1.69833214e-08 1.77714341e-08\n",
            "  7.85224064e-09 1.09290454e-09 1.74130743e-09 1.75063946e-08\n",
            "  8.22308444e-09 2.40428228e-08 8.31736546e-09 2.12472284e-09\n",
            "  3.33351089e-08 4.03500078e-09 2.90620346e-08 1.01555679e-08\n",
            "  1.00924380e-09 4.41103021e-09 8.47125747e-09 2.11824958e-08\n",
            "  9.76027525e-09 2.48435139e-09 1.92054621e-08 2.49095611e-09\n",
            "  3.87007404e-09 7.77256570e-09 4.19947588e-09 7.82322385e-09\n",
            "  1.36707556e-09 6.57571331e-09 1.20784041e-08 1.77057302e-08\n",
            "  1.17607044e-08 6.62160149e-09 2.33840023e-08 4.90802732e-09\n",
            "  1.03840732e-08 6.76696299e-09 1.39335086e-08 1.07262732e-08\n",
            "  4.10979162e-09 3.60721608e-09 1.42610157e-09 5.93680198e-08\n",
            "  1.99758454e-09 6.99335123e-09 5.84140292e-09 6.22050145e-09\n",
            "  4.90222662e-09 9.37141031e-09 8.01889577e-09 9.40010736e-09\n",
            "  5.01957302e-08 2.55424794e-07 8.33562497e-10 1.40490863e-08\n",
            "  4.68497019e-09 2.67008726e-09 1.87133131e-09 3.04425662e-09\n",
            "  8.06194400e-09 9.99999106e-01]\n",
            " [9.00347974e-09 4.52625848e-09 1.69833214e-08 1.77714341e-08\n",
            "  7.85224064e-09 1.09290454e-09 1.74130743e-09 1.75063946e-08\n",
            "  8.22308444e-09 2.40428228e-08 8.31736546e-09 2.12472284e-09\n",
            "  3.33351089e-08 4.03500078e-09 2.90620346e-08 1.01555679e-08\n",
            "  1.00924380e-09 4.41103021e-09 8.47125747e-09 2.11824958e-08\n",
            "  9.76027525e-09 2.48435139e-09 1.92054621e-08 2.49095611e-09\n",
            "  3.87007404e-09 7.77256570e-09 4.19947588e-09 7.82322385e-09\n",
            "  1.36707556e-09 6.57571331e-09 1.20784041e-08 1.77057302e-08\n",
            "  1.17607044e-08 6.62160149e-09 2.33840023e-08 4.90802732e-09\n",
            "  1.03840732e-08 6.76696299e-09 1.39335086e-08 1.07262732e-08\n",
            "  4.10979162e-09 3.60721608e-09 1.42610157e-09 5.93680198e-08\n",
            "  1.99758454e-09 6.99335123e-09 5.84140292e-09 6.22050145e-09\n",
            "  4.90222662e-09 9.37141031e-09 8.01889577e-09 9.40010736e-09\n",
            "  5.01957302e-08 2.55424794e-07 8.33562497e-10 1.40490863e-08\n",
            "  4.68497019e-09 2.67008726e-09 1.87133131e-09 3.04425662e-09\n",
            "  8.06194400e-09 9.99999106e-01]\n",
            " [1.07394382e-09 5.35026190e-10 2.35936781e-09 2.36346209e-09\n",
            "  8.00996991e-10 9.21855300e-11 1.54521063e-10 2.31439556e-09\n",
            "  8.74016581e-10 2.97594016e-09 7.83451415e-10 1.77018414e-10\n",
            "  4.75814277e-09 3.17111060e-10 3.88785537e-09 9.36290712e-10\n",
            "  8.88993115e-11 4.14573265e-10 8.58325411e-10 2.63932920e-09\n",
            "  1.01103637e-09 1.94660454e-10 2.05720596e-09 2.25796742e-10\n",
            "  3.51042057e-10 8.96595131e-10 3.38185480e-10 7.90352506e-10\n",
            "  1.21862104e-10 6.49496679e-10 1.34755418e-09 2.11672746e-09\n",
            "  1.29133593e-09 6.94716729e-10 2.96078384e-09 4.82346496e-10\n",
            "  1.03056630e-09 6.75841272e-10 1.57747704e-09 1.28270494e-09\n",
            "  3.50083240e-10 3.65214026e-10 1.36216691e-10 5.90041971e-09\n",
            "  1.50799997e-10 7.82070408e-10 4.56100213e-10 5.79678638e-10\n",
            "  5.22540622e-10 1.06849474e-09 9.61519087e-10 9.33795707e-10\n",
            "  7.19583326e-09 3.96454638e-08 6.47593715e-11 1.80359472e-09\n",
            "  4.12815226e-10 2.02482420e-10 1.75633799e-10 3.01910358e-10\n",
            "  1.08363518e-09 9.99999821e-01]]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GETTING SECOND MOST LIKELY LETTER(S) !!!"
      ],
      "metadata": {
        "id": "90THrspowcjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions for a sequence (CLDNN)\n",
        "\n",
        "# Get the prediction model by extracting layers till the output layer\n",
        "prediction_model = tf.keras.Model(\n",
        "    inputs=cldnn_model.get_layer(name='conv1d_103').input,\n",
        "    outputs=Activation('softmax')(cldnn_model.get_layer(name='time_distributed_48').output),\n",
        "    name='prediction_model'\n",
        ")\n",
        "prediction_model.summary()\n",
        "prediction_model.compile(optimizer=Adam(learning_rate=0.01), loss=ctc_loss_fn)\n",
        "\n",
        "# A utility function to decode the output of the network\n",
        "def decode_batch_predictions(pred):\n",
        "    y_pred_decoded, _ = tf.keras.ops.ctc_decode(\n",
        "    pred,\n",
        "    sequence_lengths=tf.fill([tf.shape(pred)[0]], tf.shape(pred)[1]),\n",
        "    strategy=\"beam_search\",\n",
        "    beam_width=10,  # Controls how many candidates to consider\n",
        "    top_paths=2  # Get the 2 most probable sequences\n",
        "    )\n",
        "\n",
        "    # Extract the second-best prediction (1st index in the output list)\n",
        "    second_best_pred = y_pred_decoded[1]  # Second-best prediction\n",
        "\n",
        "    # Iterate over the results and get back the text\n",
        "    output_text = []\n",
        "    for res in second_best_pred:\n",
        "        ''' print(\"res: \", res) '''\n",
        "        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n",
        "        output_text.append(res)\n",
        "        ''' print(\"output_text: \", output_text) '''\n",
        "    return output_text\n",
        "\n",
        "#  Let's check results on some samples\n",
        "for batch in val_dataset.take(1):\n",
        "    batch_sequences = batch[0]\n",
        "    batch_labels = batch[1]\n",
        "\n",
        "    preds = prediction_model.predict(batch_sequences)\n",
        "    for pred in preds[0:3]:\n",
        "        print(pred)\n",
        "    pred_texts = decode_batch_predictions(preds)\n",
        "\n",
        "    orig_texts = []\n",
        "    for label in batch_labels:\n",
        "        label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
        "        orig_texts.append(label)\n",
        "\n",
        "    for i in range(len(pred_texts)):\n",
        "      actual_text = orig_texts[i]\n",
        "      predicted_text = pred_texts[i]\n",
        "\n",
        "      # Remove [UNK]\n",
        "      actual_text = actual_text.replace(\"[UNK]\", \"\")\n",
        "      predicted_text = predicted_text.replace(\"[UNK]\", \"\")\n",
        "\n",
        "      if len(predicted_text) > 0:\n",
        "        print(\"actual text: \", actual_text)\n",
        "        print(\"predicted text: \", predicted_text)\n",
        "\n",
        "for batch in val_dataset.take(2):\n",
        "    batch_sequences = batch[0]\n",
        "    batch_labels = batch[1]\n",
        "\n",
        "    preds = prediction_model.predict(batch_sequences)\n",
        "    pred_texts = decode_batch_predictions(preds)\n",
        "\n",
        "    orig_texts = []\n",
        "    for label in batch_labels:\n",
        "        label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
        "        orig_texts.append(label)\n",
        "\n",
        "    for i in range(len(pred_texts)):\n",
        "      actual_text = orig_texts[i]\n",
        "      predicted_text = pred_texts[i]\n",
        "\n",
        "      # Remove [UNK]\n",
        "      actual_text = actual_text.replace(\"[UNK]\", \"\")\n",
        "      predicted_text = predicted_text.replace(\"[UNK]\", \"\")\n",
        "\n",
        "      if len(predicted_text) > 0:\n",
        "        print(\"actual text: \", actual_text)\n",
        "        print(\"predicted text: \", predicted_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rdRFCCCar9b0",
        "outputId": "d5a06546-598a-4dd2-e5a2-a84dc2643392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"prediction_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"prediction_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_30 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m11\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_103 (\u001b[38;5;33mConv1D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │          \u001b[38;5;34m28,672\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_121              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_121 (\u001b[38;5;33mReLU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_118 (\u001b[38;5;33mMaxPooling1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_155 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_104 (\u001b[38;5;33mConv1D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │         \u001b[38;5;34m393,472\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_122              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_122 (\u001b[38;5;33mReLU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_119 (\u001b[38;5;33mMaxPooling1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_156 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_105 (\u001b[38;5;33mConv1D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │          \u001b[38;5;34m98,432\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_123              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_123 (\u001b[38;5;33mReLU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_120 (\u001b[38;5;33mMaxPooling1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_157 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_34 (\u001b[38;5;33mBidirectional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │          \u001b[38;5;34m98,816\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_158 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_35 (\u001b[38;5;33mBidirectional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │          \u001b[38;5;34m98,816\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_159 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_47                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m100\u001b[0m)              │          \u001b[38;5;34m12,900\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_48                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m62\u001b[0m)               │           \u001b[38;5;34m6,262\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_27 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m62\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_103 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">28,672</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_121              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_121 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_118 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_155 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_104 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">393,472</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_122              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_122 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_119 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_156 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_105 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_123              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu_123 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_120 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_157 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_158 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_159 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_47                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,900</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_48                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,262</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m740,954\u001b[0m (2.83 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">740,954</span> (2.83 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m739,162\u001b[0m (2.82 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">739,162</span> (2.82 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step \n",
            "[[0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.04266094]\n",
            " [0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.04266094]\n",
            " [0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.04266094]\n",
            " [0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.04266094]\n",
            " [0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.04266094]\n",
            " [0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.04266094]\n",
            " [0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.04266094]\n",
            " [0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.04266094]]\n",
            "[[0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.04266094]\n",
            " [0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.04266094]\n",
            " [0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.04266094]\n",
            " [0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.04266094]\n",
            " [0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.04266094]\n",
            " [0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.04266094]\n",
            " [0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.04266094]\n",
            " [0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.04266094]]\n",
            "[[0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.04266094]\n",
            " [0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.04266094]\n",
            " [0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.04266094]\n",
            " [0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.04266094]\n",
            " [0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.04266094]\n",
            " [0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.04266094]\n",
            " [0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.04266094]\n",
            " [0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.01569408 0.01569408 0.01569408 0.01569408 0.01569408\n",
            "  0.01569408 0.04266094]]\n",
            "actual text:  A\n",
            "predicted text:  e\n",
            "actual text:  B\n",
            "predicted text:  e\n",
            "actual text:  C\n",
            "predicted text:  e\n",
            "actual text:  D\n",
            "predicted text:  e\n",
            "actual text:  E\n",
            "predicted text:  e\n",
            "actual text:  F\n",
            "predicted text:  e\n",
            "actual text:  G\n",
            "predicted text:  e\n",
            "actual text:  H\n",
            "predicted text:  e\n",
            "actual text:  I\n",
            "predicted text:  e\n",
            "actual text:  J\n",
            "predicted text:  e\n",
            "actual text:  K\n",
            "predicted text:  e\n",
            "actual text:  L\n",
            "predicted text:  e\n",
            "actual text:  M\n",
            "predicted text:  e\n",
            "actual text:  N\n",
            "predicted text:  e\n",
            "actual text:  O\n",
            "predicted text:  e\n",
            "actual text:  P\n",
            "predicted text:  e\n",
            "actual text:  Q\n",
            "predicted text:  e\n",
            "actual text:  R\n",
            "predicted text:  e\n",
            "actual text:  S\n",
            "predicted text:  e\n",
            "actual text:  T\n",
            "predicted text:  e\n",
            "actual text:  U\n",
            "predicted text:  e\n",
            "actual text:  V\n",
            "predicted text:  e\n",
            "actual text:  W\n",
            "predicted text:  e\n",
            "actual text:  X\n",
            "predicted text:  e\n",
            "actual text:  Y\n",
            "predicted text:  e\n",
            "actual text:  Z\n",
            "predicted text:  e\n",
            "actual text:  a\n",
            "predicted text:  e\n",
            "actual text:  b\n",
            "predicted text:  e\n",
            "actual text:  c\n",
            "predicted text:  e\n",
            "actual text:  d\n",
            "predicted text:  e\n",
            "actual text:  e\n",
            "predicted text:  e\n",
            "actual text:  f\n",
            "predicted text:  e\n",
            "actual text:  g\n",
            "predicted text:  e\n",
            "actual text:  h\n",
            "predicted text:  e\n",
            "actual text:  i\n",
            "predicted text:  e\n",
            "actual text:  j\n",
            "predicted text:  e\n",
            "actual text:  k\n",
            "predicted text:  e\n",
            "actual text:  l\n",
            "predicted text:  e\n",
            "actual text:  m\n",
            "predicted text:  e\n",
            "actual text:  n\n",
            "predicted text:  e\n",
            "actual text:  o\n",
            "predicted text:  e\n",
            "actual text:  p\n",
            "predicted text:  e\n",
            "actual text:  q\n",
            "predicted text:  e\n",
            "actual text:  r\n",
            "predicted text:  e\n",
            "actual text:  s\n",
            "predicted text:  e\n",
            "actual text:  t\n",
            "predicted text:  e\n",
            "actual text:  u\n",
            "predicted text:  e\n",
            "actual text:  v\n",
            "predicted text:  e\n",
            "actual text:  w\n",
            "predicted text:  e\n",
            "actual text:  x\n",
            "predicted text:  e\n",
            "actual text:  y\n",
            "predicted text:  e\n",
            "actual text:  z\n",
            "predicted text:  e\n",
            "actual text:  0\n",
            "predicted text:  e\n",
            "actual text:  1\n",
            "predicted text:  e\n",
            "actual text:  2\n",
            "predicted text:  e\n",
            "actual text:  3\n",
            "predicted text:  e\n",
            "actual text:  4\n",
            "predicted text:  e\n",
            "actual text:  5\n",
            "predicted text:  e\n",
            "actual text:  6\n",
            "predicted text:  e\n",
            "actual text:  7\n",
            "predicted text:  e\n",
            "actual text:  8\n",
            "predicted text:  e\n",
            "actual text:  9\n",
            "predicted text:  e\n",
            "actual text:  hi\n",
            "predicted text:  e\n",
            "actual text:  my\n",
            "predicted text:  e\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "actual text:  A\n",
            "predicted text:  e\n",
            "actual text:  B\n",
            "predicted text:  e\n",
            "actual text:  C\n",
            "predicted text:  e\n",
            "actual text:  D\n",
            "predicted text:  e\n",
            "actual text:  E\n",
            "predicted text:  e\n",
            "actual text:  F\n",
            "predicted text:  e\n",
            "actual text:  G\n",
            "predicted text:  e\n",
            "actual text:  H\n",
            "predicted text:  e\n",
            "actual text:  I\n",
            "predicted text:  e\n",
            "actual text:  J\n",
            "predicted text:  e\n",
            "actual text:  K\n",
            "predicted text:  e\n",
            "actual text:  L\n",
            "predicted text:  e\n",
            "actual text:  M\n",
            "predicted text:  e\n",
            "actual text:  N\n",
            "predicted text:  e\n",
            "actual text:  O\n",
            "predicted text:  e\n",
            "actual text:  P\n",
            "predicted text:  e\n",
            "actual text:  Q\n",
            "predicted text:  e\n",
            "actual text:  R\n",
            "predicted text:  e\n",
            "actual text:  S\n",
            "predicted text:  e\n",
            "actual text:  T\n",
            "predicted text:  e\n",
            "actual text:  U\n",
            "predicted text:  e\n",
            "actual text:  V\n",
            "predicted text:  e\n",
            "actual text:  W\n",
            "predicted text:  e\n",
            "actual text:  X\n",
            "predicted text:  e\n",
            "actual text:  Y\n",
            "predicted text:  e\n",
            "actual text:  Z\n",
            "predicted text:  e\n",
            "actual text:  a\n",
            "predicted text:  e\n",
            "actual text:  b\n",
            "predicted text:  e\n",
            "actual text:  c\n",
            "predicted text:  e\n",
            "actual text:  d\n",
            "predicted text:  e\n",
            "actual text:  e\n",
            "predicted text:  e\n",
            "actual text:  f\n",
            "predicted text:  e\n",
            "actual text:  g\n",
            "predicted text:  e\n",
            "actual text:  h\n",
            "predicted text:  e\n",
            "actual text:  i\n",
            "predicted text:  e\n",
            "actual text:  j\n",
            "predicted text:  e\n",
            "actual text:  k\n",
            "predicted text:  e\n",
            "actual text:  l\n",
            "predicted text:  e\n",
            "actual text:  m\n",
            "predicted text:  e\n",
            "actual text:  n\n",
            "predicted text:  e\n",
            "actual text:  o\n",
            "predicted text:  e\n",
            "actual text:  p\n",
            "predicted text:  e\n",
            "actual text:  q\n",
            "predicted text:  e\n",
            "actual text:  r\n",
            "predicted text:  e\n",
            "actual text:  s\n",
            "predicted text:  e\n",
            "actual text:  t\n",
            "predicted text:  e\n",
            "actual text:  u\n",
            "predicted text:  e\n",
            "actual text:  v\n",
            "predicted text:  e\n",
            "actual text:  w\n",
            "predicted text:  e\n",
            "actual text:  x\n",
            "predicted text:  e\n",
            "actual text:  y\n",
            "predicted text:  e\n",
            "actual text:  z\n",
            "predicted text:  e\n",
            "actual text:  0\n",
            "predicted text:  e\n",
            "actual text:  1\n",
            "predicted text:  e\n",
            "actual text:  2\n",
            "predicted text:  e\n",
            "actual text:  3\n",
            "predicted text:  e\n",
            "actual text:  4\n",
            "predicted text:  e\n",
            "actual text:  5\n",
            "predicted text:  e\n",
            "actual text:  6\n",
            "predicted text:  e\n",
            "actual text:  7\n",
            "predicted text:  e\n",
            "actual text:  8\n",
            "predicted text:  e\n",
            "actual text:  9\n",
            "predicted text:  e\n",
            "actual text:  hi\n",
            "predicted text:  e\n",
            "actual text:  my\n",
            "predicted text:  e\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638ms/step\n",
            "actual text:  name\n",
            "predicted text:  e\n",
            "actual text:  is\n",
            "predicted text:  e\n",
            "actual text:  tuna\n",
            "predicted text:  e\n",
            "actual text:  and\n",
            "predicted text:  e\n",
            "actual text:  i\n",
            "predicted text:  e\n",
            "actual text:  am\n",
            "predicted text:  e\n",
            "actual text:  23\n",
            "predicted text:  e\n",
            "actual text:  years\n",
            "predicted text:  e\n",
            "actual text:  old\n",
            "predicted text:  e\n",
            "actual text:  this\n",
            "predicted text:  e\n",
            "actual text:  is\n",
            "predicted text:  e\n",
            "actual text:  our\n",
            "predicted text:  e\n",
            "actual text:  first\n",
            "predicted text:  e\n",
            "actual text:  word\n",
            "predicted text:  e\n",
            "actual text:  dataset\n",
            "predicted text:  e\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b-qi2EKhvv3f"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}